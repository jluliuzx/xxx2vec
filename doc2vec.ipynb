{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the class to load the data\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self,sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        # to make sure that keys are unique\n",
    "        flipped = {}\n",
    "        for key,value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "                \n",
    "    def __iter__(self):\n",
    "        for source,prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no,line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(),[prefix + '_%s' % item_no])\n",
    "                    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source,prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no,line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(),[prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentence_perm(self):\n",
    "        shuffle(self.sentences)\n",
    "        return self.sentences\n",
    "    \n",
    "    def data_size(self):\n",
    "        self.size = len(self.sentences)\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {'test-neg.txt':'TEST_NEG','test-pos.txt':'TEST_POS','train-neg.txt':'TRAIN_NEG','train-pos.txt':'TRAIN_POS','train-unsup.txt':'TRAIN_UNS'}\n",
    "sentences = LabeledLineSentence(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(min_count=1,window=10,size=100,sample=1e-4,negative=5,workers=8)\n",
    "\n",
    "model.build_vocab(sentences.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(sentences.sentence_perm(),sentences.data_size(),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('great', 0.7953191995620728),\n",
       " ('decent', 0.7480731010437012),\n",
       " ('bad', 0.7437841296195984),\n",
       " ('nice', 0.7267850637435913),\n",
       " ('really', 0.6648749113082886),\n",
       " ('but', 0.6587772965431213),\n",
       " ('fine', 0.6404907703399658),\n",
       " ('okay', 0.6154918670654297),\n",
       " ('ok', 0.6082793474197388),\n",
       " ('solid', 0.6078991293907166)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.1449628e-02, -1.2080881e-01, -1.6393578e-02, -3.2506067e-02,\n",
       "       -1.1495809e-01,  4.1353401e-02, -1.7466456e-01,  2.5273144e-01,\n",
       "        1.2826523e-01,  6.5643370e-02, -1.3284428e-01,  9.6570075e-02,\n",
       "        2.4982466e-01, -2.9778197e-02, -2.1619467e-02, -1.3065597e-01,\n",
       "        9.4116375e-02, -3.3287060e-02,  2.8271976e-01, -3.5795206e-01,\n",
       "       -2.4556493e-02,  1.5345135e-01, -8.8969700e-02,  2.9506502e-01,\n",
       "       -5.3405393e-02,  1.7110260e-01, -1.2507200e-01, -5.5582793e-03,\n",
       "       -1.5700355e-01,  1.4176077e-02,  2.1745965e-01,  1.8602523e-01,\n",
       "       -7.8293987e-02,  1.1045813e-01,  2.7930164e-03, -3.8413096e-02,\n",
       "       -1.5410967e-04, -3.4835632e-03, -1.9273332e-01, -1.1314550e-01,\n",
       "        7.5516471e-04, -3.4545515e-02,  1.0198006e-01, -6.9790304e-02,\n",
       "        6.7190170e-02,  5.7642076e-02,  2.9831430e-02,  4.6888407e-02,\n",
       "       -1.7281073e-01,  7.2444782e-02, -2.5020510e-01,  2.5306782e-04,\n",
       "        1.5087141e-01, -6.4567998e-02, -2.5147947e-02, -1.7890921e-01,\n",
       "        8.9702517e-02, -1.5768741e-01,  4.8277359e-03, -1.2140728e-01,\n",
       "        1.6679096e-01,  1.9622868e-02, -1.3999404e-01, -2.3695122e-01,\n",
       "        1.8795842e-01,  1.6722405e-01, -2.2172827e-01, -1.3519625e-01,\n",
       "       -1.4229131e-01, -2.6040915e-01, -3.3927742e-02, -7.4744120e-02,\n",
       "       -1.7138949e-01,  8.1641905e-02, -5.0094206e-02, -4.1661758e-02,\n",
       "       -1.3805227e-01,  7.2917134e-02, -9.1463350e-02,  1.7873390e-01,\n",
       "       -1.9565497e-03,  2.3510505e-03,  1.1797866e-01,  1.7700765e-01,\n",
       "       -2.0337909e-01,  1.3636959e-01,  3.7002172e-02, -1.0267356e-02,\n",
       "        1.3335679e-01,  7.3189139e-02,  1.4510642e-01,  4.1547336e-02,\n",
       "       -3.4627949e-03, -1.4058477e-01,  9.2901856e-02,  9.0206333e-02,\n",
       "        6.6648848e-02, -1.0716554e-01,  1.3463463e-01,  6.5160632e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['TRAIN_NEG_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41424492, -0.22864938,  0.56521887,  0.09944438,  0.18952218,\n",
       "       -0.00676533, -0.13417138,  0.79027873,  0.17253539,  0.04632005,\n",
       "       -0.35245946,  0.17284836,  0.7389112 , -0.26180723,  0.01310386,\n",
       "       -0.08789073, -0.31169692, -0.04699206,  0.9776067 , -0.5450748 ,\n",
       "       -0.05935624, -0.15328032, -0.7886594 ,  0.9146491 ,  0.3332732 ,\n",
       "       -0.03769577, -0.16853772,  0.3795821 , -0.02370242,  0.16264299,\n",
       "        0.23740599,  0.4598789 ,  0.37023434,  0.12731685, -0.43478373,\n",
       "       -0.46394598, -0.28952488,  0.16053693, -0.41447666,  0.16364542,\n",
       "        0.35293925, -0.0305146 , -0.35157254,  0.40345263, -0.27706018,\n",
       "        0.5159742 ,  0.83918136, -0.32310107, -0.13694666,  0.30507025,\n",
       "       -0.29070017,  0.57944703,  0.24109359,  0.04800017,  0.2511528 ,\n",
       "       -0.62800866,  0.83147895, -0.13214229, -0.03927199, -0.50905716,\n",
       "       -0.14243847,  0.2190909 , -0.46284288, -0.13849251,  0.20964257,\n",
       "       -0.0161692 ,  0.321623  , -0.431447  , -0.07591576, -0.4820536 ,\n",
       "       -0.55174905, -0.7685055 , -0.5286931 ,  0.01887597,  0.6515921 ,\n",
       "        0.25879654, -0.08065373,  0.27357164,  0.28429165,  0.03625134,\n",
       "        0.8313671 ,  0.12580636, -0.5532835 ,  0.8114446 , -0.08856677,\n",
       "       -0.21654609,  0.7544133 , -0.0372929 , -0.61398077,  0.8967988 ,\n",
       "        0.06549655, -0.02077528, -0.4895966 ,  0.490403  ,  0.46560916,\n",
       "        0.03976752,  0.05647903, -0.19742039, -0.86218965,  0.24803145],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['TRAIN_NEG_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to construct the dataset of classification\n",
    "train_arrays = numpy.zeros((25000,100))\n",
    "train_labels = numpy.zeros(25000)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_train_pos = 'TRAIN_POS_' + str(i)\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    train_arrays[i] = model[prefix_train_pos]\n",
    "    train_arrays[12500 + i] = model[prefix_train_neg]\n",
    "    train_labels[i] = 1\n",
    "    train_labels[12500 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09243025 -0.24560335  0.28744516 ... -0.17074208 -0.10332243\n",
      "   0.23346883]\n",
      " [ 0.2137818  -0.53485626  0.03239717 ... -0.21181569 -0.07500508\n",
      "   0.17904328]\n",
      " [-0.13854299 -0.02330245  0.15953882 ... -0.12011004  0.026761\n",
      "  -0.18551254]\n",
      " ...\n",
      " [ 0.21171957 -0.01099468  0.35562286 ... -0.04002251 -0.04518218\n",
      "   0.05994232]\n",
      " [ 0.23212874 -0.27640426  0.14737687 ... -0.01750329  0.03695849\n",
      "   0.02526121]\n",
      " [ 0.13487029 -0.25067493  0.13125062 ...  0.04233909 -0.02014057\n",
      "   0.08592685]]\n"
     ]
    }
   ],
   "source": [
    "print(train_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arrays = numpy.zeros((25000,100))\n",
    "test_labels = numpy.zeros(25000)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_test_pos = 'TEST_POS_' + str(i)\n",
    "    prefix_test_neg = 'TEST_NEG_' + str(i)\n",
    "    test_arrays[i] = model[prefix_test_pos]\n",
    "    test_arrays[12500 + i] = model[prefix_test_neg]\n",
    "    test_labels[i] = 1\n",
    "    test_labels[12500 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to construct the model of classification\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84988"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays,test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
